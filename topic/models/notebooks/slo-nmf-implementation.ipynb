{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Non-Negative Matrix Factorization Topic Model Implementation on SLO Twitter Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joseph Jinn and Keith VanderLinden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and set parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the requisite libraries, custom utility functions, and set the parameters for our various imported libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries.\n",
    "import logging as log\n",
    "import warnings\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim import corpora\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyLDAvis\n",
    "from biterm.cbtm import oBTM\n",
    "from biterm.utility import vec_to_biterms, topic_summuary  # helper functions\n",
    "\n",
    "# Import custom utility functions.\n",
    "# import topic_extraction_utility_functions as lda_util\n",
    "\n",
    "#############################################################\n",
    "\n",
    "# Pandas options.\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.width = None\n",
    "pd.options.display.max_colwidth = 1000\n",
    "# Pandas float precision display.\n",
    "pd.set_option('precision', 12)\n",
    "# Seaborn setting.\n",
    "sns.set()\n",
    "# Don't output these types of warnings to terminal.\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "# Matplotlib log settings.\n",
    "mylog = log.getLogger(\"matplotlib\")\n",
    "mylog.setLevel(log.INFO)\n",
    "\n",
    "\"\"\"\n",
    "Turn debug log statements for various sections of code on/off.\n",
    "(adjust log level as necessary)\n",
    "\"\"\"\n",
    "log.basicConfig(level=log.INFO)\n",
    "log.disable(level=log.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process and Post-process Tweets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tokenize our Tweets using our dataset preprocessing and postprocessing function.  Please refer to \"topic_extraction_utility_functions.py\" for the full code-base and comments on what is done to the Tweet text and user description text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Test on our topic modeling dataset.\n",
    "tweet_dataset_preprocessor(\n",
    "    \"D:/Dropbox/summer-research-2019/jupyter-notebooks/attribute-datasets/\"\n",
    "    \"twitter-dataset-7-10-19-test-subset-100-examples.csv\",\n",
    "    \"D:/Dropbox/summer-research-2019/jupyter-notebooks/attribute-datasets/\"\n",
    "    \"twitter-dataset-7-10-19-lda-ready-tweet-text-with-hashtags-excluded-created-7-17-19.csv\",\n",
    "    \"text_derived\")\n",
    "\n",
    "# Test on our topic modeling dataset.\n",
    "tweet_dataset_preprocessor(\n",
    "    \"D:/Dropbox/summer-research-2019/jupyter-notebooks/attribute-datasets/\"\n",
    "    \"twitter-dataset-7-10-19-test-subset-100-examples.csv\",\n",
    "    \"D:/Dropbox/summer-research-2019/jupyter-notebooks/attribute-datasets/\"\n",
    "    \"twitter-dataset-7-10-19-lda-ready-user-description-text-with-hashtags-excluded-created-7-17-19.csv\",\n",
    "    \"user_description\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and prepare the preprocessed dataset for use in NMF topic extraction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We follow the general format of insertion into a Pandas dataframe, isolating the column of interest, and generating a dictionary of words and corpus of documents.  Please refer to the code comments for details on the specific steps for the entire process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # Import the dataset (relative path).\n",
    "# tweet_dataset_processed = \\\n",
    "#     pd.read_csv(\"twitter-dataset-7-10-19-lda-ready-tweet-text-with-hashtags-excluded-created-7-17-19.csv\", sep=\",\")\n",
    "\n",
    "# # Import the dataset (absolute path).\n",
    "# tweet_dataset_processed = \\\n",
    "#     pd.read_csv(\"D:/Dropbox/summer-research-2019/jupyter-notebooks/attribute-datasets/\"\n",
    "#                 \"twitter-dataset-7-10-19-lda-ready-tweet-text-with-hashtags-excluded-created-7-17-19.csv\", sep=\",\")\n",
    "\n",
    "# # Import the dataset (test/debug).\n",
    "# tweet_dataset_processed = \\\n",
    "#     pd.read_csv(\"twitter-dataset-7-10-19-lda-ready-tweet-text-test.csv\", sep=\",\")\n",
    "\n",
    "# # Import the dataset (test/debug).\n",
    "# tweet_dataset_processed = \\\n",
    "#     pd.read_csv(\"D:/Dropbox/summer-research-2019/jupyter-notebooks/attribute-datasets/\"\n",
    "#                 \"twitter-dataset-7-10-19-lda-ready-tweet-text-test.csv\", sep=\",\")\n",
    "\n",
    "# Test on a small debug dataset.\n",
    "tweet_dataset_processed = \\\n",
    "    pd.read_csv(\"D:/Dropbox/summer-research-2019/jupyter-notebooks/attribute-datasets/\"\n",
    "                \"twitter-dataset-7-10-19-topic-extraction-ready-tweet-text-test.csv\", sep=\",\")\n",
    "\n",
    "# Reindex and shuffle the data randomly.\n",
    "tweet_dataset_processed = tweet_dataset_processed.reindex(\n",
    "    pd.np.random.permutation(tweet_dataset_processed.index))\n",
    "\n",
    "# Generate a Pandas dataframe.\n",
    "tweet_text_dataframe = pd.DataFrame(tweet_dataset_processed)\n",
    "\n",
    "# # Print shape and column names.\n",
    "# log.info(f\"\\nThe shape of the Tweet text dataframe:\")\n",
    "# log.info(f\"{tweet_text_dataframe.shape}\\n\")\n",
    "# log.info(f\"\\nThe columns of the Tweet text dataframe:\")\n",
    "# log.info(f\"{tweet_text_dataframe.columns}\\n\")\n",
    "\n",
    "# Print shape and column names.\n",
    "log.info(\"\\nThe shape of the Tweet text dataframe:\")\n",
    "log.info(tweet_text_dataframe.shape)\n",
    "log.info(\"\\nThe columns of the Tweet text dataframe:\")\n",
    "log.info(tweet_text_dataframe.columns)\n",
    "\n",
    "# Drop any NaN or empty Tweet rows in dataframe (or else CountVectorizer will blow up).\n",
    "tweet_text_dataframe = tweet_text_dataframe.dropna()\n",
    "\n",
    "# # Print shape and column names.\n",
    "# log.info(f\"\\nThe shape of the Tweet text dataframe with NaN (empty) rows dropped:\")\n",
    "# log.info(f\"{tweet_text_dataframe.shape}\\n\")\n",
    "# log.info(f\"\\nThe columns of the Tweet text dataframe with NaN (empty) rows dropped:\")\n",
    "# log.info(f\"{tweet_text_dataframe.columns}\\n\")\n",
    "\n",
    "# Print shape and column names.\n",
    "log.info(\"\\nThe shape of the Tweet text dataframe with NaN (empty) rows dropped:\")\n",
    "log.info(tweet_text_dataframe.shape)\n",
    "log.info(\"\\nThe columns of the Tweet text dataframe with NaN (empty) rows dropped:\")\n",
    "log.info(tweet_text_dataframe.columns)\n",
    "\n",
    "# Reindex everything.\n",
    "tweet_text_dataframe.index = pd.RangeIndex(len(tweet_text_dataframe.index))\n",
    "\n",
    "# Assign column names.\n",
    "tweet_text_dataframe_column_names = ['text_derived', 'text_derived_preprocessed', 'text_derived_postprocessed']\n",
    "\n",
    "# Rename column in dataframe.\n",
    "tweet_text_dataframe.columns = tweet_text_dataframe_column_names\n",
    "\n",
    "# Create input feature.\n",
    "selected_features = tweet_text_dataframe[['text_derived_postprocessed']]\n",
    "processed_features = selected_features.copy()\n",
    "\n",
    "# # Check what we are using as inputs.\n",
    "# log.info(f\"\\nA sample Tweet in our input feature:\")\n",
    "# log.info(f\"{processed_features['text_derived_postprocessed'][0]}\\n\")\n",
    "\n",
    "# Check what we are using as inputs.\n",
    "log.info(\"\\nA sample Tweet in our input feature:\")\n",
    "log.info(processed_features['text_derived_postprocessed'][0])\n",
    "\n",
    "# Create feature set.\n",
    "slo_feature_series = processed_features['text_derived_postprocessed']\n",
    "slo_feature_series = pd.Series(slo_feature_series)\n",
    "slo_feature_list = slo_feature_series.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the topic extraction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function contains the code specific to each topic modeling library we utilize.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def non_negative_matrix_factorization_topic_extraction():\n",
    "    \"\"\"\n",
    "    Function performs topic extraction on Tweets using Scikit-Learn NMF model.\n",
    "\n",
    "    :return: None.\n",
    "    \"\"\"\n",
    "    from sklearn.decomposition import NMF\n",
    "\n",
    "    # Use tf-idf features for NMF.\n",
    "    print(\"\\nExtracting tf-idf features for NMF...\")\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=1000, stop_words='english')\n",
    "    tfidf = tfidf_vectorizer.fit_transform(slo_feature_series)\n",
    "    tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "    # Run NMF using Frobenius norm.\n",
    "    nmf_frobenius = NMF(n_components=20, random_state=1,\n",
    "                        alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "\n",
    "    # Run NMF using generalized Kullback-Leibler divergence.\n",
    "    nmf_kullback_leibler = NMF(n_components=20, random_state=1,\n",
    "                               beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1,\n",
    "                               l1_ratio=.5).fit(tfidf)\n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Display the top words for each topic.\n",
    "    print(\"\\nTopics using NMF Frobenius norm:\")\n",
    "    topic_util.display_topics(nmf_frobenius, tfidf_feature_names, 10)\n",
    "\n",
    "    # Display the top words for each topic.\n",
    "    print(\"\\nTopics using generalized Kullback-Leibler divergence:\")\n",
    "    topic_util.display_topics(nmf_kullback_leibler, tfidf_feature_names, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we call the topic modeling function and train it on our Twitter dataset.  We record the time it takes to process the entire dataset and extract topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main function.  Execute the program.\n",
    "\"\"\"\n",
    "if __name__ == '__main__':\n",
    "    my_start_time = time.time()\n",
    "    ################################################\n",
    "    \"\"\"\n",
    "    Perform exhaustive grid search.\n",
    "    \"\"\"\n",
    "    # FIXME - non functional unless we find a way to disable cross-validation \"cv\" parameter in GridSearchCV Class.\n",
    "    # What parameters do we search for?\n",
    "    lda_search_parameters = {\n",
    "        'vect__strip_accents': [None],\n",
    "        'vect__lowercase': [True],\n",
    "        'vect__stop_words': ['english'],\n",
    "        # 'vect__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)],\n",
    "        'vect__analyzer': ['word'],\n",
    "        'vect__min_df': [2],\n",
    "        'vect__max_df': [0.95],\n",
    "        'vect__max_features': [1000],\n",
    "        'clf__n_components': [5, 10, 20],\n",
    "        'clf__init': ['random', 'nndsvd', 'nndsvda', 'nndsvdar'],\n",
    "        'clf__solver': ['cd', 'mu'],\n",
    "        'clf__beta_loss': ['frobenius', 'kullback-leibler', 'itakura-saito'],\n",
    "        'clf__tol': [1e-2, 1e-4, 1e-6],\n",
    "        'clf__max_iter': [100, 200, 300],\n",
    "        'clf__alpha': [0],\n",
    "        'clf__l1_ratio': [0],\n",
    "        'clf__verbose': [False],\n",
    "        'clf__shuffle': [False],\n",
    "        'clf__random_state': [None],\n",
    "    }\n",
    "    # topic_util.non_negative_matrix_factorization_grid_search(slo_feature_series, lda_search_parameters)\n",
    "    \"\"\"\n",
    "    Perform exhaustive grid search on data subset.\n",
    "    \"\"\"\n",
    "    # data_subset = topic_util.dataframe_subset(tweet_dataset_processed, 50)\n",
    "    # topic_util.non_negative_matrix_factorization_grid_search(data_subset, lda_search_parameters)\n",
    "\n",
    "    \"\"\"\n",
    "    Perform the topic extraction.\n",
    "    \"\"\"\n",
    "    # non_negative_matrix_factorization_topic_extraction()\n",
    "\n",
    "    ################################################\n",
    "    my_end_time = time.time()\n",
    "\n",
    "    time_elapsed_in_seconds = (my_end_time - my_start_time)\n",
    "    time_elapsed_in_minutes = (my_end_time - my_start_time) / 60.0\n",
    "    time_elapsed_in_hours = (my_end_time - my_start_time) / 60.0 / 60.0\n",
    "    # print(f\"Time taken to process dataset: {time_elapsed_in_seconds} seconds, \"\n",
    "    #       f\"{time_elapsed_in_minutes} minutes, {time_elapsed_in_hours} hours.\")\n",
    "    print(\"\\n\\nTime taken to process dataset: \" + str(time_elapsed_in_seconds) + \" seconds, \" +\n",
    "          str(time_elapsed_in_minutes) + \" minutes, \" + str(time_elapsed_in_hours) + \" hours.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Extraction Results on Twitter Dataset Tweet Text:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution run 1."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "NMF Output:\n",
    "\n",
    "(run 1)\n",
    "Topics using NMF Frobenius norm:\n",
    "Topic 0:\n",
    "adani turnbull india queensland ahead oppose indian water deal point\n",
    "Topic 1:\n",
    "rio tinto iron ore bulga new expansion uk sell london\n",
    "Topic 2:\n",
    "santos pilliga csg tour dos los narrabri plan home forest\n",
    "Topic 3:\n",
    "bhp billiton iron ore dam price brazil share cut australian\n",
    "Topic 4:\n",
    "coal new india power build price seam world kill point\n",
    "Topic 5:\n",
    "job 000 create 10 tourism thousand lie qld renewable energy\n",
    "Topic 6:\n",
    "reef great barrier artesian basin kill save destroy trust coral\n",
    "Topic 7:\n",
    "stop land destroy people culture vote native greens title win\n",
    "Topic 8:\n",
    "australia world future wake big large risk energy india thing\n",
    "Topic 9:\n",
    "carmichael need coalmine federal court approval land report culture queensland\n",
    "Topic 10:\n",
    "tax pay year slo_cash haven company fortescue ato corporate profit\n",
    "Topic 11:\n",
    "whitehaven beach creek maules forest day photo island protest clear\n",
    "Topic 12:\n",
    "project narrabri mega shorten bank ahead csg halt announce rt\n",
    "Topic 13:\n",
    "½í ¼í ½í² ¼í¼ ¾í slo_mention slo_hash ½í¹ think slo_cash\n",
    "Topic 14:\n",
    "gas nsw water seam narrabri field farmer pilliga pipeline land\n",
    "Topic 15:\n",
    "climate change time action policy risk future new slo_mention join\n",
    "Topic 16:\n",
    "want australian people know billion dollar future listen mega govt\n",
    "Topic 17:\n",
    "fund loan government taxpayer rail money naif public line bank\n",
    "Topic 18:\n",
    "woodside petroleum road oil lng price downer news search energy\n",
    "Topic 19:\n",
    "labor support qld vote lnp greens election shorten alp party\n",
    "\n",
    "Topics using generalized Kullback-Leibler divergence:\n",
    "Topic 0:\n",
    "adani loan government minister turnbull india canavan face ahead question\n",
    "Topic 1:\n",
    "rio tinto iron ore bhp business close new mining fall\n",
    "Topic 2:\n",
    "santos gas nsw pilliga narrabri csg barnaby forest farmer water\n",
    "Topic 3:\n",
    "bhp billiton ceo dam disaster loss cut brazil boss asx\n",
    "Topic 4:\n",
    "coal new india build power open port dirty solar giant\n",
    "Topic 5:\n",
    "job 000 destroy create 10 lie real pm tourism claim\n",
    "Topic 6:\n",
    "great reef barrier help fight right world join kill basin\n",
    "Topic 7:\n",
    "stop labor election lnp vote greens win alp qld shorten\n",
    "Topic 8:\n",
    "australia energy future big clean industry thing demand planet fossil\n",
    "Topic 9:\n",
    "adani carmichael court coalmine approval land native challenge title owner\n",
    "Topic 10:\n",
    "pay tax company money billion cut dollar indian million billionaire\n",
    "Topic 11:\n",
    "whitehaven day beach protest anti iluka thank stand morning brisbane\n",
    "Topic 12:\n",
    "project ½í breaking finance decision china bank board ¼í wo\n",
    "Topic 13:\n",
    "support good party leave carbon policy issue huge fact mean\n",
    "Topic 14:\n",
    "fortescue environmental group galilee basin price away cost record happen\n",
    "Topic 15:\n",
    "people time slo_mention action come look work think power live\n",
    "Topic 16:\n",
    "want need know ahead let mega tell people listen govt\n",
    "Topic 17:\n",
    "fund climate change bank public federal report risk taxpayer money\n",
    "Topic 18:\n",
    "australian woodside news late oil thanks share video times sentinel\n",
    "Topic 19:\n",
    "qld water queensland govt government year point build deal line\n",
    "\n",
    "\n",
    "Time taken to process dataset: 306.614928483963 seconds, 5.11024880806605 minutes, 0.0851708134677675 hours.\n",
    "\n",
    "\n",
    "Process finished with exit code 0\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution run 2."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "(run 2)\n",
    "Topics using NMF Frobenius norm:\n",
    "Topic 0:\n",
    "adani turnbull india queensland ahead oppose indian water deal point\n",
    "Topic 1:\n",
    "rio tinto iron ore bulga new expansion uk sell london\n",
    "Topic 2:\n",
    "santos pilliga csg tour dos los narrabri plan home forest\n",
    "Topic 3:\n",
    "bhp billiton iron ore dam price brazil share cut australian\n",
    "Topic 4:\n",
    "coal new india power build price seam world kill point\n",
    "Topic 5:\n",
    "job 000 create 10 tourism thousand lie qld renewable energy\n",
    "Topic 6:\n",
    "reef great barrier artesian basin kill save destroy trust coral\n",
    "Topic 7:\n",
    "stop land destroy people culture vote native greens title win\n",
    "Topic 8:\n",
    "australia world future wake big large risk energy india thing\n",
    "Topic 9:\n",
    "carmichael need coalmine federal court approval land report culture queensland\n",
    "Topic 10:\n",
    "tax pay year slo_cash haven company fortescue ato corporate profit\n",
    "Topic 11:\n",
    "whitehaven beach creek maules forest day photo island protest clear\n",
    "Topic 12:\n",
    "project narrabri mega shorten bank ahead csg halt announce rt\n",
    "Topic 13:\n",
    "½í ¼í ½í² ¼í¼ ¾í slo_mention slo_hash ½í¹ think slo_cash\n",
    "Topic 14:\n",
    "gas nsw water seam narrabri field farmer pilliga pipeline land\n",
    "Topic 15:\n",
    "climate change time action policy risk future new slo_mention join\n",
    "Topic 16:\n",
    "want australian people know billion dollar future listen mega govt\n",
    "Topic 17:\n",
    "fund loan government taxpayer rail money naif public line bank\n",
    "Topic 18:\n",
    "woodside petroleum road oil lng price downer news search energy\n",
    "Topic 19:\n",
    "labor support qld vote lnp greens election shorten alp party\n",
    "\n",
    "Topics using generalized Kullback-Leibler divergence:\n",
    "Topic 0:\n",
    "adani loan minister turnbull government canavan india face ahead corruption\n",
    "Topic 1:\n",
    "rio tinto iron ore business bhp new close fall miner\n",
    "Topic 2:\n",
    "santos gas nsw pilliga narrabri csg barnaby forest farmer water\n",
    "Topic 3:\n",
    "bhp billiton ceo dam disaster loss brazil cut asx boss\n",
    "Topic 4:\n",
    "coal new india build power port dirty solar import plan\n",
    "Topic 5:\n",
    "job 000 destroy create 10 lie tourism real pm thousand\n",
    "Topic 6:\n",
    "great reef barrier help fight right join world kill basin\n",
    "Topic 7:\n",
    "stop labor election lnp vote greens win alp shorten qld\n",
    "Topic 8:\n",
    "australia energy future big clean industry demand thing planet country\n",
    "Topic 9:\n",
    "adani carmichael court coalmine approval land title native report challenge\n",
    "Topic 10:\n",
    "pay tax company money billion cut dollar million indian billionaire\n",
    "Topic 11:\n",
    "whitehaven day beach protest anti iluka stand thank morning creek\n",
    "Topic 12:\n",
    "project ½í breaking finance decision china board investment slo_hash ¼í\n",
    "Topic 13:\n",
    "support good party leave carbon issue policy huge mean fact\n",
    "Topic 14:\n",
    "fortescue environmental group galilee basin cost away price record happen\n",
    "Topic 15:\n",
    "people time slo_mention action come look work think power live\n",
    "Topic 16:\n",
    "want need know ahead let tell mega govt community listen\n",
    "Topic 17:\n",
    "fund climate change bank public federal report risk government taxpayer\n",
    "Topic 18:\n",
    "australian woodside news late oil thanks share home times sentinel\n",
    "Topic 19:\n",
    "qld water queensland govt government year deal point build line\n",
    "\n",
    "\n",
    "Time taken to process dataset: 323.3131334781647 seconds, 5.3885522246360775 minutes, 0.08980920374393463 hours.\n",
    "\n",
    "\n",
    "Process finished with exit code 0\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the fastest of our topic modeling algorithms.  Most of the time was spend generating term-frequencies for the entire dataset.  The output shows the results for two different types of learning utilizing non-negative matrix factorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources Used:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html\n",
    "    - Scikit-Learn example of NMF and LDA.\n",
    "    \n",
    "    \n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html#sklearn.decomposition.NMF\n",
    "    - Scikit-Learn API documentation on NMF.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
