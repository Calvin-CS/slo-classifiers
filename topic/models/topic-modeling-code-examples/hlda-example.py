"""
..................................................50
topic=0 level=0 (documents=401): peopl, use, mobil, technolog, phone,
    topic=1 level=1 (documents=342): game, develop, world, time, comput,
        topic=2 level=2 (documents=228): secur, system, user, softwar, data,
        topic=3 level=2 (documents=48): blog, gadget, appl, mac, mini,
        topic=4 level=2 (documents=18): robot, music, musician, vehicl, court,
        topic=7 level=2 (documents=30): law, patent, comput, softwar, use,
        topic=10 level=2 (documents=18): messag, blogger, send, multimedia, compani,
    topic=5 level=1 (documents=59): world, appl, game, onlin, say,
        topic=6 level=2 (documents=17): attack, site, traffic, net, data,
        topic=8 level=2 (documents=42): search, user, googl, microsoft, web,

..................................................100
topic=0 level=0 (documents=401): peopl, use, mobil, phone, technolog,
    topic=1 level=1 (documents=306): game, comput, world, develop, time,
        topic=2 level=2 (documents=176): secur, user, program, softwar, system,
        topic=3 level=2 (documents=48): blog, gadget, mac, thi, appl,
        topic=4 level=2 (documents=21): robot, music, musician, record, vehicl,
        topic=7 level=2 (documents=32): law, patent, use, european, direct,
        topic=10 level=2 (documents=29): china, blogger, websit, site, multimedia,
    topic=5 level=1 (documents=95): game, world, make, say, one,
        topic=6 level=2 (documents=36): attack, site, net, use, traffic,
        topic=8 level=2 (documents=59): search, user, googl, web, site,

..................................................150
topic=0 level=0 (documents=401): peopl, mobil, phone, technolog, use,
    topic=1 level=1 (documents=305): game, comput, world, develop, work,
        topic=2 level=2 (documents=167): secur, user, use, program, softwar,
        topic=3 level=2 (documents=48): blog, gadget, thi, mac, list,
        topic=4 level=2 (documents=25): robot, music, san, record, andrea,
        topic=7 level=2 (documents=38): law, use, patent, european, dvd,
        topic=10 level=2 (documents=27): china, messag, one, blogger, laptop,
    topic=5 level=1 (documents=96): game, world, make, work, new,
        topic=6 level=2 (documents=38): attack, site, use, net, traffic,
        topic=8 level=2 (documents=58): search, user, googl, inform, web,

..................................................200
topic=0 level=0 (documents=401): peopl, mobil, technolog, phone, use,
    topic=1 level=1 (documents=298): game, comput, develop, world, thi,
        topic=2 level=2 (documents=157): secur, user, program, softwar, system,
        topic=3 level=2 (documents=49): blog, gadget, appl, mac, list,
        topic=4 level=2 (documents=27): robot, music, record, san, andrea,
        topic=7 level=2 (documents=36): law, dvd, patent, would, european,
        topic=10 level=2 (documents=29): china, one, blogger, messag, multimedia,
    topic=5 level=1 (documents=103): game, world, make, time, develop,
        topic=6 level=2 (documents=38): attack, use, site, data, traffic,
        topic=8 level=2 (documents=65): search, user, googl, web, site,

..................................................250
topic=0 level=0 (documents=401): peopl, mobil, phone, technolog, servic,
    topic=1 level=1 (documents=295): game, comput, world, develop, new,
        topic=2 level=2 (documents=153): secur, program, user, site, softwar,
        topic=3 level=2 (documents=50): blog, gadget, thi, list, mac,
        topic=4 level=2 (documents=27): robot, soni, record, music, nintendo,
        topic=7 level=2 (documents=34): technolog, law, dvd, patent, european,
        topic=10 level=2 (documents=31): china, messag, blogger, one, countri,
    topic=5 level=1 (documents=106): game, develop, time, year, make,
        topic=6 level=2 (documents=38): use, attack, site, data, net,
        topic=8 level=2 (documents=68): search, user, web, googl, inform,

..................................................300
topic=0 level=0 (documents=401): peopl, mobil, phone, technolog, use,
    topic=1 level=1 (documents=294): game, comput, develop, world, thi,
        topic=2 level=2 (documents=148): secur, user, program, use, softwar,
        topic=3 level=2 (documents=48): blog, gadget, mini, list, thi,
        topic=4 level=2 (documents=31): robot, soni, record, electron, sale,
        topic=7 level=2 (documents=35): technolog, law, patent, dvd, use,
        topic=10 level=2 (documents=32): messag, china, blogger, news, one,
    topic=5 level=1 (documents=107): game, make, world, work, time,
        topic=6 level=2 (documents=40): use, attack, site, data, net,
        topic=8 level=2 (documents=67): search, user, googl, inform, web,

..................................................350
topic=0 level=0 (documents=401): peopl, mobil, technolog, phone, servic,
    topic=1 level=1 (documents=294): game, comput, thi, world, use,
        topic=2 level=2 (documents=145): secur, user, program, system, softwar,
        topic=3 level=2 (documents=48): blog, gadget, mac, list, mini,
        topic=4 level=2 (documents=31): robot, game, soni, nintendo, record,
        topic=7 level=2 (documents=37): dvd, law, highdefinit, patent, format,
        topic=10 level=2 (documents=33): one, messag, china, commodor, blogger,
    topic=5 level=1 (documents=107): game, develop, make, thi, world,
        topic=6 level=2 (documents=40): use, attack, site, data, net,
        topic=8 level=2 (documents=67): search, user, googl, inform, web,

..................................................400
topic=0 level=0 (documents=401): peopl, mobil, phone, technolog, servic,
    topic=1 level=1 (documents=296): game, comput, thi, use, world,
        topic=2 level=2 (documents=145): secur, user, program, system, firm,
        topic=3 level=2 (documents=47): blog, gadget, mac, list, appl,
        topic=4 level=2 (documents=34): game, robot, nintendo, soni, consol,
        topic=7 level=2 (documents=38): dvd, law, highdefinit, format, technolog,
        topic=10 level=2 (documents=32): china, commodor, blogger, laptop, million,
    topic=5 level=1 (documents=105): game, world, technolog, make, work,
        topic=6 level=2 (documents=40): use, attack, site, data, net,
        topic=8 level=2 (documents=65): search, user, peopl, inform, googl,

..................................................450
topic=0 level=0 (documents=401): peopl, mobil, technolog, phone, servic,
    topic=1 level=1 (documents=293): game, thi, use, comput, world,
        topic=2 level=2 (documents=141): secur, user, program, softwar, site,
        topic=3 level=2 (documents=47): blog, gadget, list, mini, appl,
        topic=4 level=2 (documents=34): game, robot, nintendo, soni, consol,
        topic=7 level=2 (documents=40): dvd, law, highdefinit, technolog, patent,
        topic=10 level=2 (documents=31): china, messag, commodor, blogger, million,
    topic=5 level=1 (documents=108): game, make, could, play, one,
        topic=6 level=2 (documents=42): use, attack, data, site, net,
        topic=8 level=2 (documents=66): search, user, web, inform, googl,

..................................................500
topic=0 level=0 (documents=401): peopl, mobil, phone, technolog, servic,
    topic=1 level=1 (documents=293): game, comput, use, thi, one,
        topic=2 level=2 (documents=138): secur, program, user, site, microsoft,
        topic=3 level=2 (documents=47): blog, gadget, game, mac, appl,
        topic=4 level=2 (documents=37): game, nintendo, soni, consol, robot,
        topic=7 level=2 (documents=39): dvd, law, highdefinit, technolog, european,
        topic=10 level=2 (documents=32): messag, china, commodor, blogger, laptop,
    topic=5 level=1 (documents=108): game, make, say, world, one,
        topic=6 level=2 (documents=42): use, data, attack, site, network,
        topic=8 level=2 (documents=66): search, user, peopl, web, inform,

Time taken to process dataset: 2997.1069991588593 seconds, 49.95178331931432 minutes, 0.832529721988572 hours.

Process finished with exit code 0
"""

# %load_ext autoreload
# %autoreload 2
# %matplotlib inline

import sys
import os
import time

basedir = 'D:/Dropbox/summer-research-2019/topic-modeling-code-examples/'
sys.path.append(os.path.join(basedir))

import pylab as plt
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from wordcloud import WordCloud
from hlda.sampler import HierarchicalLDA
from ipywidgets import widgets
from IPython.core.display import HTML, display
import numpy as np
import string
import glob

nltk.download('stopwords')
nltk.download('punkt')

########################################################################################################

# Stop words.
stopset = stopwords.words('english') + list(string.punctuation) + ['will', 'also', 'said']

# Data structures.
corpus = []
all_docs = []
vocab = set()

# Parse through files and create the initial dictionary and corpus.
stemmer = PorterStemmer()
for filename in glob.glob(os.path.join(basedir, 'bbc', 'tech', '*.txt')):
    with open(filename) as f:
        try:

            doc = f.read().splitlines()
            doc = filter(None, doc)  # remove empty string
            doc = '. '.join(doc)

            to_remove = string.punctuation
            table = str.maketrans("", "", to_remove)
            doc = doc.translate(table)  # strip punctuations

            to_remove = "0123456789"
            table = str.maketrans("", "", to_remove)
            doc = doc.translate(table)  # strip numbers

            doc = doc.encode("utf8").decode('ascii', 'ignore')  # ignore fancy unicode chars
            all_docs.append(doc)

            tokens = word_tokenize(str(doc))
            filtered = []
            for w in tokens:
                w = stemmer.stem(w.lower())  # use Porter's stemmer
                if len(w) < 3:  # remove short tokens
                    continue
                if w in stopset:  # remove stop words
                    continue
                filtered.append(w)

            vocab.update(filtered)
            corpus.append(filtered)

        except UnicodeDecodeError:
            print('Failed to load', filename)

print("\nDone parsing files and creating the initial dictionary and corpus.")

#####################################################

# Create the dictionary.
vocab = sorted(list(vocab))
vocab_index = {}
for i, w in enumerate(vocab):
    vocab_index[w] = i

print(f"\nThe number of documents: {len(all_docs)}")

print(f"\nThe number of words in the dictionary: {len(vocab)}")
print(f"Sample of the words in the dictionary:\n {vocab[0:100]}")

print(f"\nThe number of documents in the corpus: {len(corpus)}")
print(f"Sample of the documents in the corpus:\n {corpus}")

# Visualize the dictionary of words.
wordcloud = WordCloud(background_color='white').generate(' '.join(all_docs))
plt.figure(figsize=(12, 12))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.show()

print(f"\nLength of the dictionary, corpus, document 0 in corpus, document 1 in corpus (in that order)")
print(len(vocab), len(corpus), len(corpus[0]), len(corpus[1]))

# Create the corpus.
new_corpus = []
for doc in corpus:
    new_doc = []
    for word in doc:
        word_idx = vocab_index[word]
        new_doc.append(word_idx)
    new_corpus.append(new_doc)

print(f"\nLength of the dictionary and corpus (as word dictionary index values (in that order))")
print(len(vocab), len(new_corpus))


print(f"\nDocument 0 in the corpus as tokenized words:")
print(corpus[0][0:10])
print(f"Document 0 in the corpus as tokenized word index values from the dictionary:")
print(new_corpus[0][0:10])

print(f"\nDocument 1 in the corpus as tokenized words:")
print(corpus[1][0:10])
print(f"Document 1 in the corpus as tokenized word index values from the dictionary:")
print(new_corpus[1][0:10])

print(f"\nDocument 2 in the corpus as tokenized words:")
print(corpus[2][0:10])
print(f"Document 2 in the corpus as tokenized word index values from the dictionary:")
print(new_corpus[2][0:10])

########################################################################################################

# Set parameters.
n_samples = 500  # no of iterations for the sampler
alpha = 10.0  # smoothing over level distributions
gamma = 1.0  # CRP smoothing parameter; number of imaginary customers at next, as yet unused table
eta = 0.1  # smoothing over topic-word distributions
num_levels = 3  # the number of levels in the tree
display_topics = 50  # the number of iterations between printing a brief summary of the topics so far
n_words = 5  # the number of most probable words to print for each topic after model estimation
with_weights = False  # whether to print the words with the weights

my_start_time = time.time()

# Execute HLDA algorithm.
hlda = HierarchicalLDA(new_corpus, vocab, alpha=alpha, gamma=gamma, eta=eta, num_levels=num_levels)
# hlda.estimate(n_samples, display_topics=display_topics, n_words=n_words, with_weights=with_weights)

my_end_time = time.time()

# Time program took to execute.
time_elapsed_in_seconds = (my_end_time - my_start_time)
time_elapsed_in_minutes = (my_end_time - my_start_time) / 60.0
time_elapsed_in_hours = (my_end_time - my_start_time) / 60.0 / 60.0
print(f"Time taken to process dataset: {time_elapsed_in_seconds} seconds, "
      f"{time_elapsed_in_minutes} minutes, {time_elapsed_in_hours} hours.")

########################################################################################################
